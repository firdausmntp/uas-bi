{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "full_code_cell"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 1. EXTRACT DATA ]\n",
            "Initial Shape : (9800, 18) (Rows, Cols)\n",
            "Columns       : ['Row ID', 'Order ID', 'Order Date', 'Ship Date', 'Ship Mode', 'Customer ID', 'Customer Name', 'Segment', 'Country', 'City', 'State', 'Postal Code', 'Region', 'Product ID', 'Category', 'Sub-Category', 'Product Name', 'Sales']\n",
            "\n",
            "[ 2. CLEANING ]\n",
            "\n",
            "--- BEFORE CLEANING ---\n",
            "Shape: (9800, 18)\n",
            "Missing Values:\n",
            "Postal Code    11\n",
            "dtype: int64\n",
            "First 3 rows:\n",
            "   Row ID        Order ID  Order Date   Ship Date     Ship Mode Customer ID  \\\n",
            "0       1  CA-2017-152156  08/11/2017  11/11/2017  Second Class    CG-12520   \n",
            "1       2  CA-2017-152156  08/11/2017  11/11/2017  Second Class    CG-12520   \n",
            "2       3  CA-2017-138688  12/06/2017  16/06/2017  Second Class    DV-13045   \n",
            "\n",
            "     Customer Name    Segment        Country         City       State  \\\n",
            "0      Claire Gute   Consumer  United States    Henderson    Kentucky   \n",
            "1      Claire Gute   Consumer  United States    Henderson    Kentucky   \n",
            "2  Darrin Van Huff  Corporate  United States  Los Angeles  California   \n",
            "\n",
            "   Postal Code Region       Product ID         Category Sub-Category  \\\n",
            "0      42420.0  South  FUR-BO-10001798        Furniture    Bookcases   \n",
            "1      42420.0  South  FUR-CH-10000454        Furniture       Chairs   \n",
            "2      90036.0   West  OFF-LA-10000240  Office Supplies       Labels   \n",
            "\n",
            "                                        Product Name   Sales  \n",
            "0                  Bush Somerset Collection Bookcase  261.96  \n",
            "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.94  \n",
            "2  Self-Adhesive Address Labels for Typewriters b...   14.62  \n",
            "\n",
            "--- AFTER CLEANING ---\n",
            "Shape: (9800, 18)\n",
            "Missing Values:\n",
            "Series([], dtype: int64)\n",
            "First 3 rows (Cleaned):\n",
            "   Row ID        Order ID Order Date  Ship Date     Ship Mode Customer ID  \\\n",
            "0       1  CA-2017-152156 2017-11-08 2017-11-11  Second Class    CG-12520   \n",
            "1       2  CA-2017-152156 2017-11-08 2017-11-11  Second Class    CG-12520   \n",
            "2       3  CA-2017-138688 2017-06-12 2017-06-16  Second Class    DV-13045   \n",
            "\n",
            "     Customer Name    Segment        Country         City       State  \\\n",
            "0      Claire Gute   Consumer  United States    Henderson    Kentucky   \n",
            "1      Claire Gute   Consumer  United States    Henderson    Kentucky   \n",
            "2  Darrin Van Huff  Corporate  United States  Los Angeles  California   \n",
            "\n",
            "  Postal Code Region       Product ID         Category Sub-Category  \\\n",
            "0       42420  South  FUR-BO-10001798        Furniture    Bookcases   \n",
            "1       42420  South  FUR-CH-10000454        Furniture       Chairs   \n",
            "2       90036   West  OFF-LA-10000240  Office Supplies       Labels   \n",
            "\n",
            "                                        Product Name   Sales  \n",
            "0                  Bush Somerset Collection Bookcase  261.96  \n",
            "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.94  \n",
            "2  Self-Adhesive Address Labels for Typewriters b...   14.62  \n",
            "✔ Dates converted & Missing values handled\n",
            "\n",
            "[ 3. CREATING KEYS (18 -> 20 Cols) ]\n",
            "Menambahkan 2 kolom helper (key) untuk kebutuhan join Star Schema:\n",
            "  1. region_key: Gabungan Region + State + City\n",
            "  2. product_key: Gabungan Product ID + Product Name\n",
            "New Shape     : (9800, 20) (Total 20 Kolom sekarang)\n",
            "\n",
            "[ 4. GENERATING DIMENSIONS ]\n",
            "✔ Dimensions Created: Date(1464), Customer(793), Product(1893), Region(600)\n",
            "\n",
            "[ 5. GENERATING FACT TABLE ]\n",
            "✔ Fact Table Created: (9800, 7)\n",
            "  Columns: ['order_id', 'sk_order_date', 'sk_ship_date', 'sk_customer', 'sk_product', 'sk_region', 'sales']\n",
            "\n",
            "[ 6. VALIDATION & SAVING ]\n",
            "Total Missing SKs : 0 (Should be 0)\n",
            "✔ All files saved successfully.\n",
            "ETL PROCES COMPLETED.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. EXTRACT & SETUP\n",
        "# ==============================================================================\n",
        "print(\"[ 1. EXTRACT DATA ]\")\n",
        "df = pd.read_csv('train.csv')\n",
        "\n",
        "print(f\"Initial Shape : {df.shape} (Rows, Cols)\")\n",
        "print(\"Columns       :\", list(df.columns))\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. DATA CLEANING & PREPROCESSING\n",
        "# ==============================================================================\n",
        "print(\"\\n[ 2. CLEANING ]\")\n",
        "print(\"\\n--- BEFORE CLEANING ---\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "missing_before = df.isnull().sum()\n",
        "print(f\"Missing Values:\\n{missing_before[missing_before > 0]}\")\n",
        "print(\"First 3 rows:\")\n",
        "print(df.head(3))\n",
        "\n",
        "# Convert date columns to datetime objects\n",
        "df['Order Date'] = pd.to_datetime(df['Order Date'], dayfirst=True, errors='coerce')\n",
        "df['Ship Date']  = pd.to_datetime(df['Ship Date'], dayfirst=True, errors='coerce')\n",
        "\n",
        "# Handle Missing Values (Postal Code)\n",
        "postal_mean = df['Postal Code'].mean()\n",
        "df['Postal Code'] = df['Postal Code'].fillna(postal_mean).astype(int).astype(str)\n",
        "\n",
        "print(\"\\n--- AFTER CLEANING ---\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "missing_after = df.isnull().sum()\n",
        "print(f\"Missing Values:\\n{missing_after[missing_after > 0]}\")  # Should be empty\n",
        "print(\"First 3 rows (Cleaned):\")\n",
        "print(df.head(3))\n",
        "print(\"✔ Dates converted & Missing values handled\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. FEATURE ENGINEERING (ALASAN 18 KOLOM -> 20 KOLOM)\n",
        "# ==============================================================================\n",
        "print(\"\\n[ 3. CREATING KEYS (18 -> 20 Cols) ]\")\n",
        "print(\"Menambahkan 2 kolom helper (key) untuk kebutuhan join Star Schema:\")\n",
        "print(\"  1. region_key: Gabungan Region + State + City\")\n",
        "print(\"  2. product_key: Gabungan Product ID + Product Name\")\n",
        "\n",
        "# Membuat Unique Key untuk Region\n",
        "df['region_key'] = (\n",
        "    df['Region'].astype(str) + '-' +\n",
        "    df['State'].astype(str) + '-' +\n",
        "    df['City'].astype(str)\n",
        ")\n",
        "\n",
        "# Membuat Unique Key untuk Product\n",
        "df['product_key'] = (\n",
        "    df['Product ID'].astype(str) + '-' +\n",
        "    df['Product Name'].astype(str)\n",
        ")\n",
        "\n",
        "print(f\"New Shape     : {df.shape} (Total 20 Kolom sekarang)\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. CREATE DIMENSION TABLES\n",
        "# ==============================================================================\n",
        "print(\"\\n[ 4. GENERATING DIMENSIONS ]\")\n",
        "\n",
        "# --- DIM_DATE ---\n",
        "date_range = pd.date_range(\n",
        "    start=df[['Order Date','Ship Date']].min().min(),\n",
        "    end=df[['Order Date','Ship Date']].max().max()\n",
        ")\n",
        "dim_date = pd.DataFrame({'date': date_range})\n",
        "dim_date['sk_date']     = dim_date['date'].dt.strftime('%Y%m%d').astype(int)\n",
        "dim_date['year']        = dim_date['date'].dt.year\n",
        "dim_date['month_num']   = dim_date['date'].dt.month\n",
        "dim_date['month_name']  = dim_date['date'].dt.strftime('%B')\n",
        "dim_date['quarter']     = dim_date['date'].dt.quarter\n",
        "dim_date['day_of_week'] = dim_date['date'].dt.strftime('%A')\n",
        "dim_date = dim_date[['sk_date', 'date', 'year', 'month_num', 'month_name', 'quarter', 'day_of_week']]\n",
        "\n",
        "# --- DIM_CUSTOMER ---\n",
        "dim_customer = df[['Customer ID', 'Customer Name', 'Segment']].drop_duplicates().reset_index(drop=True)\n",
        "dim_customer['sk_customer'] = dim_customer.index + 1\n",
        "dim_customer = dim_customer[['sk_customer', 'Customer ID', 'Customer Name', 'Segment']]\n",
        "dim_customer.columns = ['sk_customer', 'customer_id', 'customer_name', 'segment']\n",
        "\n",
        "# --- DIM_PRODUCT ---\n",
        "dim_product = df[['Product ID', 'Product Name', 'Category', 'Sub-Category', 'product_key']].drop_duplicates(subset=['product_key']).reset_index(drop=True)\n",
        "dim_product['sk_product'] = dim_product.index + 1\n",
        "dim_product = dim_product[['sk_product', 'Product ID', 'Product Name', 'Category', 'Sub-Category', 'product_key']]\n",
        "dim_product.columns = ['sk_product', 'product_id', 'product_name', 'category', 'sub_category', 'product_key']\n",
        "\n",
        "# --- DIM_REGION ---\n",
        "dim_region = df[['Region', 'Country', 'State', 'City', 'region_key']].drop_duplicates(subset=['region_key']).reset_index(drop=True)\n",
        "dim_region['sk_region'] = dim_region.index + 1\n",
        "dim_region = dim_region[['sk_region', 'Region', 'Country', 'State', 'City', 'region_key']]\n",
        "dim_region.columns = ['sk_region', 'region', 'country', 'state', 'city', 'region_key']\n",
        "\n",
        "print(f\"✔ Dimensions Created: Date({len(dim_date)}), Customer({len(dim_customer)}), Product({len(dim_product)}), Region({len(dim_region)})\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 5. CREATE FACT TABLE\n",
        "# ==============================================================================\n",
        "print(\"\\n[ 5. GENERATING FACT TABLE ]\")\n",
        "fact_sales = df.copy()\n",
        "\n",
        "# Merge with Dimensions to get Surrogate Keys (SK)\n",
        "fact_sales = fact_sales.merge(dim_date[['sk_date', 'date']], left_on='Order Date', right_on='date', how='left').rename(columns={'sk_date': 'sk_order_date'}).drop(columns=['date'])\n",
        "fact_sales = fact_sales.merge(dim_date[['sk_date', 'date']], left_on='Ship Date', right_on='date', how='left').rename(columns={'sk_date': 'sk_ship_date'}).drop(columns=['date'])\n",
        "fact_sales = fact_sales.merge(dim_customer[['sk_customer', 'customer_id']], left_on='Customer ID', right_on='customer_id', how='left').drop(columns=['customer_id'])\n",
        "fact_sales = fact_sales.merge(dim_product[['sk_product', 'product_key']], on='product_key', how='left')\n",
        "fact_sales = fact_sales.merge(dim_region[['sk_region', 'region_key']], on='region_key', how='left')\n",
        "\n",
        "# Select only Fact Columns (Include Profit & Quantity as per Rubric)\n",
        "# Check if Profit/Quantity exists (Standard Superstore), otherwise handle gracefully\n",
        "cols_to_keep = ['Order ID', 'sk_order_date', 'sk_ship_date', 'sk_customer', 'sk_product', 'sk_region', 'Sales']\n",
        "if 'Profit' in df.columns:\n",
        "    cols_to_keep.append('Profit')\n",
        "if 'Quantity' in df.columns:\n",
        "    cols_to_keep.append('Quantity')\n",
        "if 'Discount' in df.columns:\n",
        "    cols_to_keep.append('Discount')\n",
        "\n",
        "fact_sales = fact_sales[cols_to_keep]\n",
        "\n",
        "# Rename columns to snake_case\n",
        "col_map = {\n",
        "    'Order ID': 'order_id',\n",
        "    'Order Date': 'order_date',\n",
        "    'Sales': 'sales',\n",
        "    'Profit': 'profit',\n",
        "    'Quantity': 'quantity',\n",
        "    'Discount': 'discount'\n",
        "}\n",
        "fact_sales.rename(columns=col_map, inplace=True)\n",
        "\n",
        "print(f\"✔ Fact Table Created: {fact_sales.shape}\")\n",
        "print(f\"  Columns: {list(fact_sales.columns)}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 6. VALIDATION & SAVING\n",
        "# ==============================================================================\n",
        "print(\"\\n[ 6. VALIDATION & SAVING ]\")\n",
        "missing_sks = fact_sales[['sk_customer', 'sk_product', 'sk_region', 'sk_order_date', 'sk_ship_date']].isna().sum().sum()\n",
        "print(f\"Total Missing SKs : {missing_sks} (Should be 0)\")\n",
        "\n",
        "# Save files\n",
        "dim_date.to_csv('dim_date.csv', index=False)\n",
        "dim_customer.to_csv('dim_customer.csv', index=False)\n",
        "dim_product.to_csv('dim_product.csv', index=False)\n",
        "dim_region.to_csv('dim_region.csv', index=False)\n",
        "fact_sales.to_csv('fact_sales.csv', index=False)\n",
        "\n",
        "print(\"✔ All files saved successfully.\")\n",
        "print(\"ETL PROCES COMPLETED.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
